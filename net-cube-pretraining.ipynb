{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib notebook \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from src.mesh.cube import NetCube, to_vertices\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch3d.structures.meshes.Meshes at 0x7f8db1d0a750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted = to_vertices(torch.load('./data/centered_32_32.pt')).to(device)\n",
    "# Load the dolphin mesh.\n",
    "trg_obj = os.path.join('./data/scenes/centered/meshes/centered.obj')\n",
    "\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "# center = verts.mean(0)\n",
    "# verts = verts - center\n",
    "# scale = max(verts.abs().max(0)[0])\n",
    "# verts = verts / scale\n",
    "\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])#.to(device)\n",
    "trg_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([6144, 3]), torch.Size([12284, 3])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch3d.structures.meshes.Meshes at 0x7f8d279738d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Namespace(\n",
    "    n = 82,\n",
    "    nfc=64, \n",
    "    min_nfc=64, \n",
    "    ker_size=3,\n",
    "    num_layer=5,\n",
    "    stride=1,\n",
    "    padd_size=0,\n",
    "    nc_im=3,\n",
    ")\n",
    "\n",
    "n = 32\n",
    "cube = NetCube(n, opt, kernel=7, sigma=2).to(device)\n",
    "\n",
    "#radii = torch.rand(3, device=v_ref.device, requires_grad=True)\n",
    "v, f = cube()\n",
    "# n_ref = compute_face_normals(v_ref, f_ref)\n",
    "print([f.shape for f in [v, f]])\n",
    "\n",
    "start = cube.get_start().to(device)\n",
    "src_mesh =  Meshes(verts=[start], faces=[f])\n",
    "src_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6144, 3]), torch.Size([6144, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.get_start().shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.7598,  0.2454, -0.1011],\n",
       "          [ 0.4518,  0.3388, -0.5362],\n",
       "          [-0.4601,  0.0573, -0.4956],\n",
       "          ...,\n",
       "          [-0.2578,  0.9072, -0.4133],\n",
       "          [ 0.2198, -0.4969, -0.5312],\n",
       "          [ 0.6108, -0.6324,  0.1658]]], device='cuda:0'),\n",
       " tensor([[[-0.7310,  0.4013,  0.0498],\n",
       "          [ 0.1120, -0.7909,  0.2986],\n",
       "          [-0.3991,  0.4612, -0.6683],\n",
       "          ...,\n",
       "          [-0.4673,  0.4728, -0.8830],\n",
       "          [-0.3563,  0.0799, -0.0345],\n",
       "          [-0.2652, -0.2571,  1.1032]]], device='cuda:0',\n",
       "        grad_fn=<IndexPutBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
    "new_src_mesh = src_mesh.offset_verts(v)\n",
    "sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
    "sample_trg, sample_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0003\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizer = torch.optim.SGD(cube.parameters(), lr=1.0, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(cube.parameters(), lr=0.0003)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab95f43f32440319c066e0744dc09a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of optimization steps\n",
    "Niter = 5000\n",
    "\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    v, _ = cube()\n",
    "    \n",
    "    verts = v + start\n",
    "    loss = F.mse_loss(verts, fitted)\n",
    "    #loss = loss_chamfer\n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "#     chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "#     edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "#     normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "#     laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    #if i % plot_period == 0:\n",
    "    #    plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#chamfer_losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cube.net.state_dict(), './data/net_fitted_n32_c64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d054eee6c0e242f7b0f669afd84c805c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.052400â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f8d27973510>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import meshplot\n",
    "\n",
    "vert =  cube.get_start().to(device) + v\n",
    "meshplot.plot(vert.detach().cpu().numpy(), f.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12620a431ad4180a458c4e79ff93fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobi/miniconda3/envs/conjure/lib/python3.7/site-packages/pytorch3d/structures/meshes.py:1108: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self._edges_packed = torch.stack([u // V, u % V], dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08580422401428223,\n",
       " 0.11131545156240463,\n",
       " 0.11299756169319153,\n",
       " 0.09337344020605087,\n",
       " 0.10640192031860352,\n",
       " 0.06829623878002167,\n",
       " 0.09871694445610046,\n",
       " 0.07358501106500626,\n",
       " 0.08694301545619965,\n",
       " 0.06982751935720444,\n",
       " 0.07825282961130142,\n",
       " 0.06410867720842361,\n",
       " 0.043873079121112823,\n",
       " 0.06362723559141159,\n",
       " 0.029885444790124893,\n",
       " 0.03428409993648529,\n",
       " 0.031234625726938248,\n",
       " 0.02693854086101055,\n",
       " 0.025703150779008865,\n",
       " 0.01998584158718586,\n",
       " 0.01962932199239731,\n",
       " 0.02028483711183071,\n",
       " 0.018270572647452354,\n",
       " 0.017216715961694717,\n",
       " 0.016716625541448593,\n",
       " 0.014117913320660591,\n",
       " 0.012886292301118374,\n",
       " 0.011267879977822304,\n",
       " 0.012165969237685204,\n",
       " 0.010828897356987,\n",
       " 0.009888475760817528,\n",
       " 0.009792844764888287,\n",
       " 0.009122336283326149,\n",
       " 0.010015508159995079,\n",
       " 0.0093916617333889,\n",
       " 0.009002873674035072,\n",
       " 0.00825746264308691,\n",
       " 0.007931019179522991,\n",
       " 0.007783900480717421,\n",
       " 0.007359719835221767,\n",
       " 0.006989621557295322,\n",
       " 0.006963356398046017,\n",
       " 0.0070494553074240685,\n",
       " 0.006698760204017162,\n",
       " 0.006549471989274025,\n",
       " 0.006263387389481068,\n",
       " 0.0060046277940273285,\n",
       " 0.005855509079992771,\n",
       " 0.005511424969881773,\n",
       " 0.005338397808372974,\n",
       " 0.005275703966617584,\n",
       " 0.00517662288621068,\n",
       " 0.005073602311313152,\n",
       " 0.004961035214364529,\n",
       " 0.004726054146885872,\n",
       " 0.004689935594797134,\n",
       " 0.004620118997991085,\n",
       " 0.004699887707829475,\n",
       " 0.004530988167971373,\n",
       " 0.004362806677818298,\n",
       " 0.004446023143827915,\n",
       " 0.004413507413119078,\n",
       " 0.004532207734882832,\n",
       " 0.004203450866043568,\n",
       " 0.004247593227773905,\n",
       " 0.004101180005818605,\n",
       " 0.004063093103468418,\n",
       " 0.0041939024813473225,\n",
       " 0.004002319183200598,\n",
       " 0.0038531366735696793,\n",
       " 0.0038614915683865547,\n",
       " 0.003934248350560665,\n",
       " 0.00384919554926455,\n",
       " 0.0037071704864501953,\n",
       " 0.003679882735013962,\n",
       " 0.0036661187186837196,\n",
       " 0.0036677811294794083,\n",
       " 0.003654804080724716,\n",
       " 0.003616779111325741,\n",
       " 0.003570549888536334,\n",
       " 0.003492552787065506,\n",
       " 0.0034867897629737854,\n",
       " 0.0034724404104053974,\n",
       " 0.003456168808043003,\n",
       " 0.0035112465266138315,\n",
       " 0.003420085646212101,\n",
       " 0.0034306433517485857,\n",
       " 0.0034356131218373775,\n",
       " 0.003310256637632847,\n",
       " 0.003466501599177718,\n",
       " 0.0033254502341151237,\n",
       " 0.0033452212810516357,\n",
       " 0.0034260042011737823,\n",
       " 0.003386283293366432,\n",
       " 0.003364621428772807,\n",
       " 0.003376419423148036,\n",
       " 0.0033399579115211964,\n",
       " 0.0032631256617605686,\n",
       " 0.00334949535317719,\n",
       " 0.003249559085816145,\n",
       " 0.0033486324828118086,\n",
       " 0.003252889961004257,\n",
       " 0.003304416546598077,\n",
       " 0.0032147099263966084,\n",
       " 0.003263666294515133,\n",
       " 0.00336760887876153,\n",
       " 0.0032248664647340775,\n",
       " 0.003130657598376274,\n",
       " 0.003190743736922741,\n",
       " 0.0031891060061752796,\n",
       " 0.0032937079668045044,\n",
       " 0.00314660114236176,\n",
       " 0.003327201586216688,\n",
       " 0.0031350580975413322,\n",
       " 0.003270423971116543,\n",
       " 0.0031229699961841106,\n",
       " 0.0032175462692976,\n",
       " 0.003171494696289301,\n",
       " 0.0032570394687354565,\n",
       " 0.003137443447485566,\n",
       " 0.003053888911381364,\n",
       " 0.0031347842887043953,\n",
       " 0.0031235371716320515,\n",
       " 0.0031161224469542503,\n",
       " 0.0030130650848150253,\n",
       " 0.0030854942742735147,\n",
       " 0.0030589706730097532,\n",
       " 0.003034460823982954,\n",
       " 0.0030395574867725372,\n",
       " 0.0030586582142859697,\n",
       " 0.0030169179663062096,\n",
       " 0.0030753472819924355,\n",
       " 0.00304509699344635,\n",
       " 0.0030139260925352573,\n",
       " 0.002989751286804676,\n",
       " 0.0029747290536761284,\n",
       " 0.003025645390152931,\n",
       " 0.002913803094998002,\n",
       " 0.002969072200357914,\n",
       " 0.002899479353800416,\n",
       " 0.0029755847062915564,\n",
       " 0.0029823523946106434,\n",
       " 0.002943158382549882,\n",
       " 0.0028863060288131237,\n",
       " 0.0028228091541677713,\n",
       " 0.002885277383029461,\n",
       " 0.002956379670649767,\n",
       " 0.002957743126899004,\n",
       " 0.0027723624370992184,\n",
       " 0.0028926029335707426,\n",
       " 0.002901067491620779,\n",
       " 0.002954343566671014,\n",
       " 0.0028065957594662905,\n",
       " 0.002918696729466319,\n",
       " 0.0027842801064252853,\n",
       " 0.002868336159735918,\n",
       " 0.002850248944014311,\n",
       " 0.0027721705846488476,\n",
       " 0.00290417717769742,\n",
       " 0.002859655534848571,\n",
       " 0.0027095885016024113,\n",
       " 0.0027437040116637945,\n",
       " 0.0027629544492810965,\n",
       " 0.0028462959453463554,\n",
       " 0.002910700161010027,\n",
       " 0.0026941178366541862,\n",
       " 0.0027729948051273823,\n",
       " 0.0027687218971550465,\n",
       " 0.0028256443329155445,\n",
       " 0.0027557197026908398,\n",
       " 0.002783320378512144,\n",
       " 0.0026861217338591814,\n",
       " 0.0028042541816830635,\n",
       " 0.002760129515081644,\n",
       " 0.0027158348821103573,\n",
       " 0.0027045602910220623,\n",
       " 0.002669659908860922,\n",
       " 0.002758587710559368,\n",
       " 0.002662169747054577,\n",
       " 0.0027811680920422077,\n",
       " 0.0026361793279647827,\n",
       " 0.002714594127610326,\n",
       " 0.002653777366504073,\n",
       " 0.002624095883220434,\n",
       " 0.002619562204927206,\n",
       " 0.0026811212301254272,\n",
       " 0.0026169028133153915,\n",
       " 0.0025736079551279545,\n",
       " 0.002651080721989274,\n",
       " 0.0026244320906698704,\n",
       " 0.002660871483385563,\n",
       " 0.002581103704869747,\n",
       " 0.0025556283071637154,\n",
       " 0.0025513102300465107,\n",
       " 0.0026520914398133755,\n",
       " 0.0025863891933113337,\n",
       " 0.002652747556567192,\n",
       " 0.0026215030811727047,\n",
       " 0.0025862683542072773,\n",
       " 0.0025636511854827404,\n",
       " 0.0025226203724741936,\n",
       " 0.0025320020504295826,\n",
       " 0.0025448398664593697,\n",
       " 0.0025353459641337395,\n",
       " 0.0025911456905305386,\n",
       " 0.0025318730622529984,\n",
       " 0.0025551693979650736,\n",
       " 0.002558069536462426,\n",
       " 0.0025363564491271973,\n",
       " 0.002503320574760437,\n",
       " 0.002562939655035734,\n",
       " 0.0024996213614940643,\n",
       " 0.002553066238760948,\n",
       " 0.0025969978887587786,\n",
       " 0.00242045009508729,\n",
       " 0.00243503600358963,\n",
       " 0.0024310932494699955,\n",
       " 0.0024139073211699724,\n",
       " 0.002514745807275176,\n",
       " 0.0025206420104950666,\n",
       " 0.0024566338397562504,\n",
       " 0.002434845780953765,\n",
       " 0.0024582305923104286,\n",
       " 0.002442037221044302,\n",
       " 0.00246044690720737,\n",
       " 0.0024756616912782192,\n",
       " 0.0025244150310754776,\n",
       " 0.002363568637520075,\n",
       " 0.0024393051862716675,\n",
       " 0.002395634539425373,\n",
       " 0.0025164945982396603,\n",
       " 0.002484649885445833,\n",
       " 0.0024407547898590565,\n",
       " 0.002436591312289238,\n",
       " 0.0024815050419420004,\n",
       " 0.0024545681662857533,\n",
       " 0.002365203108638525,\n",
       " 0.0024012248031795025,\n",
       " 0.0024822480045259,\n",
       " 0.002439984818920493,\n",
       " 0.0024295966140925884,\n",
       " 0.002332686446607113,\n",
       " 0.002439824864268303,\n",
       " 0.0024251705035567284,\n",
       " 0.0024532941170036793,\n",
       " 0.002424458507448435,\n",
       " 0.0024395466316491365,\n",
       " 0.002395237097516656,\n",
       " 0.002435748465359211,\n",
       " 0.002455831505358219,\n",
       " 0.0025493314024060965,\n",
       " 0.0023913758341223,\n",
       " 0.002440734300762415,\n",
       " 0.0024730509612709284,\n",
       " 0.0023251622915267944,\n",
       " 0.0023542772978544235,\n",
       " 0.0023333621211349964,\n",
       " 0.00236380728892982,\n",
       " 0.0023375735618174076,\n",
       " 0.0023600198328495026,\n",
       " 0.002407799242064357,\n",
       " 0.002380882389843464,\n",
       " 0.0023076701909303665,\n",
       " 0.002325791399925947,\n",
       " 0.0023344664368778467,\n",
       " 0.002430863678455353,\n",
       " 0.0023377928882837296,\n",
       " 0.0022813365794718266,\n",
       " 0.002403438091278076,\n",
       " 0.002398380544036627,\n",
       " 0.00226931506767869,\n",
       " 0.0023153789807111025,\n",
       " 0.002369111403822899,\n",
       " 0.0023278803564608097,\n",
       " 0.0024081128649413586,\n",
       " 0.002351976465433836,\n",
       " 0.0024167613591998816,\n",
       " 0.002339063910767436,\n",
       " 0.0022915485315024853,\n",
       " 0.002414530608803034,\n",
       " 0.002338558901101351,\n",
       " 0.0023837159387767315,\n",
       " 0.0023275057319551706,\n",
       " 0.0023333493154495955,\n",
       " 0.0023656522389501333,\n",
       " 0.0022856462746858597,\n",
       " 0.0023231753148138523,\n",
       " 0.002316963393241167,\n",
       " 0.0023543457500636578,\n",
       " 0.0023169005289673805,\n",
       " 0.0022728736512362957,\n",
       " 0.0023330189287662506,\n",
       " 0.002285064198076725,\n",
       " 0.0024065314792096615,\n",
       " 0.002296071033924818,\n",
       " 0.002380046993494034,\n",
       " 0.002306362148374319,\n",
       " 0.002258575987070799,\n",
       " 0.0023002903908491135,\n",
       " 0.002267240546643734,\n",
       " 0.002303697634488344,\n",
       " 0.0022475519217550755,\n",
       " 0.0022796017583459616,\n",
       " 0.00241282326169312,\n",
       " 0.002294038888067007,\n",
       " 0.002267627278342843,\n",
       " 0.002313473727554083,\n",
       " 0.002322044223546982,\n",
       " 0.0023173210211098194,\n",
       " 0.0022615944035351276,\n",
       " 0.0022662775591015816,\n",
       " 0.002244081813842058,\n",
       " 0.002219889545813203,\n",
       " 0.002256538951769471,\n",
       " 0.002279747510328889,\n",
       " 0.002272302284836769,\n",
       " 0.002245670650154352,\n",
       " 0.002316018333658576,\n",
       " 0.002249710261821747,\n",
       " 0.0022537652403116226,\n",
       " 0.0022673215717077255,\n",
       " 0.0022477104794234037,\n",
       " 0.002255947794765234,\n",
       " 0.002257279586046934,\n",
       " 0.002254154998809099,\n",
       " 0.00223701074719429,\n",
       " 0.00226063234731555,\n",
       " 0.0022704810835421085,\n",
       " 0.0021702537778764963,\n",
       " 0.0023345453664660454,\n",
       " 0.002313951263204217,\n",
       " 0.002231826540082693,\n",
       " 0.002391017507761717,\n",
       " 0.002313431352376938,\n",
       " 0.002341745886951685,\n",
       " 0.0022648382000625134,\n",
       " 0.0023766462691128254,\n",
       " 0.002270542550832033,\n",
       " 0.002292597433552146,\n",
       " 0.002214999170973897,\n",
       " 0.0022804492618888617,\n",
       " 0.00224423804320395,\n",
       " 0.002269281540066004,\n",
       " 0.0022107181139290333,\n",
       " 0.002289985539391637,\n",
       " 0.0022585829719901085,\n",
       " 0.002223174087703228,\n",
       " 0.002265290357172489,\n",
       " 0.0022823233157396317,\n",
       " 0.0023080201353877783,\n",
       " 0.0022908090613782406,\n",
       " 0.0022564714308828115,\n",
       " 0.0022671145852655172,\n",
       " 0.0022987322881817818,\n",
       " 0.002191880252212286,\n",
       " 0.0023177536204457283,\n",
       " 0.0023317132145166397,\n",
       " 0.0021565756760537624,\n",
       " 0.0022568819113075733,\n",
       " 0.0022798446007072926,\n",
       " 0.002311559859663248,\n",
       " 0.002260483568534255,\n",
       " 0.002342608291655779,\n",
       " 0.0023453820031136274,\n",
       " 0.0022305892780423164,\n",
       " 0.0023201974108815193,\n",
       " 0.0023366245441138744,\n",
       " 0.0022486932575702667,\n",
       " 0.0021988339722156525,\n",
       " 0.0023751878179609776,\n",
       " 0.0022095420863479376,\n",
       " 0.002325555309653282,\n",
       " 0.00224491860717535,\n",
       " 0.002276796381920576,\n",
       " 0.0022164778783917427,\n",
       " 0.0022655464708805084,\n",
       " 0.0022984673269093037,\n",
       " 0.002307266928255558,\n",
       " 0.0021984842605888844,\n",
       " 0.0022225934080779552,\n",
       " 0.002243190538138151,\n",
       " 0.002178179332986474,\n",
       " 0.0022314279340207577,\n",
       " 0.002196358982473612,\n",
       " 0.0022139823995530605,\n",
       " 0.002193846506997943,\n",
       " 0.0021659424528479576,\n",
       " 0.002165548037737608,\n",
       " 0.0022524730302393436,\n",
       " 0.0022620130330324173,\n",
       " 0.002231271006166935,\n",
       " 0.002186420140787959,\n",
       " 0.0022120620124042034,\n",
       " 0.002193593420088291,\n",
       " 0.002222607843577862,\n",
       " 0.002192765474319458,\n",
       " 0.0021881461143493652,\n",
       " 0.002219419926404953,\n",
       " 0.0022053252905607224,\n",
       " 0.0022464862558990717,\n",
       " 0.0022190194576978683,\n",
       " 0.002158689545467496,\n",
       " 0.00224470067769289,\n",
       " 0.0021371215116232634,\n",
       " 0.0021604534704238176,\n",
       " 0.0021568499505519867,\n",
       " 0.0021915712859481573,\n",
       " 0.0020991864148527384,\n",
       " 0.00218987837433815,\n",
       " 0.0021426102612167597,\n",
       " 0.0021586348302662373,\n",
       " 0.0021312229800969362,\n",
       " 0.002173322718590498,\n",
       " 0.0021060463041067123,\n",
       " 0.002183077856898308,\n",
       " 0.0022505680099129677,\n",
       " 0.002174624241888523,\n",
       " 0.002280871383845806,\n",
       " 0.0021629841066896915,\n",
       " 0.0022271317429840565,\n",
       " 0.002235491294413805,\n",
       " 0.0021837661042809486,\n",
       " 0.0021664495579898357,\n",
       " 0.0023390776477754116,\n",
       " 0.002329586073756218,\n",
       " 0.00226867338642478,\n",
       " 0.002273739781230688,\n",
       " 0.0022356677800416946,\n",
       " 0.002190065337345004,\n",
       " 0.002247029449790716,\n",
       " 0.0021793304476886988,\n",
       " 0.002360671991482377,\n",
       " 0.002176843583583832,\n",
       " 0.0021742908284068108,\n",
       " 0.0022206834983080626,\n",
       " 0.002133114030584693,\n",
       " 0.0022228211164474487,\n",
       " 0.0021661086939275265,\n",
       " 0.002209003083407879,\n",
       " 0.0021901705767959356,\n",
       " 0.00215280894190073,\n",
       " 0.002150123007595539,\n",
       " 0.0022006449289619923,\n",
       " 0.00221269391477108,\n",
       " 0.0021887095645070076,\n",
       " 0.0022699248511344194,\n",
       " 0.002252175472676754,\n",
       " 0.0022363627795130014,\n",
       " 0.0022466678638011217,\n",
       " 0.0022381015587598085,\n",
       " 0.002149655483663082,\n",
       " 0.002177804708480835,\n",
       " 0.002250518649816513,\n",
       " 0.0021859449334442616,\n",
       " 0.0020808172412216663,\n",
       " 0.0021496110130101442,\n",
       " 0.002154331188648939,\n",
       " 0.0020836556795984507,\n",
       " 0.002155119087547064,\n",
       " 0.0021076505072414875,\n",
       " 0.002137998351827264,\n",
       " 0.002100075129419565,\n",
       " 0.002146458486095071,\n",
       " 0.0021545770578086376,\n",
       " 0.0021100519225001335,\n",
       " 0.0021921107545495033,\n",
       " 0.0021359010133892298,\n",
       " 0.002080231672152877,\n",
       " 0.00218947883695364,\n",
       " 0.0020727370865643024,\n",
       " 0.0021735532209277153,\n",
       " 0.0023499897215515375,\n",
       " 0.002379580168053508,\n",
       " 0.002324420027434826,\n",
       " 0.0023345041554421186,\n",
       " 0.0021206247620284557,\n",
       " 0.002165897050872445,\n",
       " 0.0022456166334450245,\n",
       " 0.0023599443957209587,\n",
       " 0.0024345903657376766,\n",
       " 0.002355267759412527,\n",
       " 0.0022585075348615646,\n",
       " 0.002210624050348997,\n",
       " 0.002194324042648077,\n",
       " 0.002332734875380993,\n",
       " 0.0023014741018414497,\n",
       " 0.0023400108329951763,\n",
       " 0.0023062352556735277,\n",
       " 0.0021539730951189995,\n",
       " 0.002122502774000168,\n",
       " 0.0022918693721294403,\n",
       " 0.0022550029680132866,\n",
       " 0.0023880640510469675,\n",
       " 0.002335993107408285,\n",
       " 0.002329518087208271,\n",
       " 0.0021033785305917263,\n",
       " 0.0021799998357892036,\n",
       " 0.002137325005605817,\n",
       " 0.002137555507943034,\n",
       " 0.002120602410286665,\n",
       " 0.0021138153970241547,\n",
       " 0.0021015312522649765,\n",
       " 0.0021104677580296993,\n",
       " 0.002077267039567232,\n",
       " 0.0020730530377477407,\n",
       " 0.0020921940449625254,\n",
       " 0.0020557353273034096,\n",
       " 0.002091498812660575,\n",
       " 0.002090111607685685,\n",
       " 0.002087414264678955,\n",
       " 0.0021624823566526175,\n",
       " 0.0020946497097611427,\n",
       " 0.002127924235537648,\n",
       " 0.0021809593308717012,\n",
       " 0.0020962022244930267,\n",
       " 0.0021749581210315228,\n",
       " 0.002124754711985588,\n",
       " 0.00213344837538898,\n",
       " 0.0022248015739023685,\n",
       " 0.0022597694769501686,\n",
       " 0.0022125658579170704,\n",
       " 0.0021515036933124065,\n",
       " 0.0021096777636557817,\n",
       " 0.002097097225487232,\n",
       " 0.0020841180812567472,\n",
       " 0.00211888924241066,\n",
       " 0.0020467734429985285,\n",
       " 0.0021238415502011776,\n",
       " 0.002117716707289219,\n",
       " 0.0021671063732355833,\n",
       " 0.002152421046048403,\n",
       " 0.0021263849921524525,\n",
       " 0.002170541323721409,\n",
       " 0.0020088169258087873,\n",
       " 0.0021375473588705063,\n",
       " 0.002041087718680501,\n",
       " 0.00210612453520298,\n",
       " 0.0021561519242823124,\n",
       " 0.0020656962879002094,\n",
       " 0.0020379899069666862,\n",
       " 0.002075532916933298,\n",
       " 0.002147246152162552,\n",
       " 0.002192761981859803,\n",
       " 0.0021774873603135347,\n",
       " 0.0022232523187994957,\n",
       " 0.0021336423233151436,\n",
       " 0.002088072942569852,\n",
       " 0.0021300348453223705,\n",
       " 0.00207232846878469,\n",
       " 0.00213555246591568,\n",
       " 0.0021814897190779448,\n",
       " 0.0021847127936780453,\n",
       " 0.0021953615359961987,\n",
       " 0.002277710475027561,\n",
       " 0.0023147561587393284,\n",
       " 0.002248442266136408,\n",
       " 0.002146597020328045,\n",
       " 0.002209844533354044,\n",
       " 0.0023072734475135803,\n",
       " 0.0022922991774976254,\n",
       " 0.002089713467285037,\n",
       " 0.002162403892725706,\n",
       " 0.002159983618184924,\n",
       " 0.002176330192014575,\n",
       " 0.0021283458918333054,\n",
       " 0.002122787991538644,\n",
       " 0.002118213102221489,\n",
       " 0.002046604873612523,\n",
       " 0.002085284097120166,\n",
       " 0.0021123131737113,\n",
       " 0.0022138399071991444,\n",
       " 0.0021969880908727646,\n",
       " 0.0022085406817495823,\n",
       " 0.0021658409386873245,\n",
       " 0.002043031621724367,\n",
       " 0.0020957973320037127,\n",
       " 0.0022453642450273037,\n",
       " 0.0024215392768383026,\n",
       " 0.002316821366548538,\n",
       " 0.0021770899184048176,\n",
       " 0.0021590478718280792,\n",
       " 0.002183513715863228,\n",
       " 0.00222695991396904,\n",
       " 0.00216570682823658,\n",
       " 0.002066927496343851,\n",
       " 0.0020492810290306807,\n",
       " 0.002248466946184635,\n",
       " 0.002329915529116988,\n",
       " 0.0023380573838949203,\n",
       " 0.002096164505928755,\n",
       " 0.002052717376500368,\n",
       " 0.002092931652441621,\n",
       " 0.0021191020496189594,\n",
       " 0.002169274725019932,\n",
       " 0.002128858584910631,\n",
       " 0.0020466777496039867,\n",
       " 0.0020207015331834555,\n",
       " 0.0020500735845416784,\n",
       " 0.0021204128861427307,\n",
       " 0.002148041734471917,\n",
       " 0.002074114279821515,\n",
       " 0.0020529301837086678,\n",
       " 0.0021980111487209797,\n",
       " 0.002134417649358511,\n",
       " 0.002139793708920479,\n",
       " 0.0020817089825868607,\n",
       " 0.0020718141458928585,\n",
       " 0.0021743876859545708,\n",
       " 0.002170229097828269,\n",
       " 0.00213730544783175,\n",
       " 0.0020796661265194416,\n",
       " 0.0020649582147598267,\n",
       " 0.0020865220576524734,\n",
       " 0.0021117795258760452,\n",
       " 0.002117605647072196,\n",
       " 0.0020904738921672106,\n",
       " 0.0021428337786346674,\n",
       " 0.0020755580626428127,\n",
       " 0.0021041512954980135,\n",
       " 0.002077780431136489,\n",
       " 0.002086648717522621,\n",
       " 0.0021785832941532135,\n",
       " 0.002144353464245796,\n",
       " 0.0020686457864940166,\n",
       " 0.0020699547603726387,\n",
       " 0.002142072655260563,\n",
       " 0.0021297927014529705,\n",
       " 0.0021549067460000515,\n",
       " 0.002144179306924343,\n",
       " 0.0021565642673522234,\n",
       " 0.0021645657252520323,\n",
       " 0.0020993975922465324,\n",
       " 0.002150587737560272,\n",
       " 0.002131127053871751,\n",
       " 0.0020433212630450726,\n",
       " 0.002148763742297888,\n",
       " 0.0021296865306794643,\n",
       " 0.0022570735309273005,\n",
       " 0.0021334909833967686,\n",
       " 0.001976277679204941,\n",
       " 0.002031938638538122,\n",
       " 0.002080093137919903,\n",
       " 0.0021366924047470093,\n",
       " 0.00219200667925179,\n",
       " 0.0020629828795790672,\n",
       " 0.002257890533655882,\n",
       " 0.0024087480269372463,\n",
       " 0.002184914890676737,\n",
       " 0.0020059538073837757,\n",
       " 0.0021759287919849157,\n",
       " 0.002349551534280181,\n",
       " 0.0022996189072728157,\n",
       " 0.0022325916215777397,\n",
       " 0.002203847747296095,\n",
       " 0.0021193416323512793,\n",
       " 0.002171921543776989,\n",
       " 0.002248272532597184,\n",
       " 0.0023118327371776104,\n",
       " 0.002075601601973176,\n",
       " 0.00212808046489954,\n",
       " 0.002193107735365629,\n",
       " 0.00233517587184906,\n",
       " 0.002368554472923279,\n",
       " 0.0023779410403221846,\n",
       " 0.0021336213685572147,\n",
       " 0.002054499927908182,\n",
       " 0.0021237474866211414,\n",
       " 0.0023401377256959677,\n",
       " 0.0021667226683348417,\n",
       " 0.0020729992538690567,\n",
       " 0.002310276497155428,\n",
       " 0.0021262927912175655,\n",
       " 0.002237631008028984,\n",
       " 0.0022479165345430374,\n",
       " 0.002217336092144251,\n",
       " 0.0022125444374978542,\n",
       " 0.002058645011857152,\n",
       " 0.0021741243544965982,\n",
       " 0.0020954180508852005,\n",
       " 0.0020990942139178514,\n",
       " 0.002074546180665493,\n",
       " 0.002044228371232748,\n",
       " 0.0021212128922343254,\n",
       " 0.001958065200597048,\n",
       " 0.002025466412305832,\n",
       " 0.001969435717910528,\n",
       " 0.0019143985118716955,\n",
       " 0.001982268411666155,\n",
       " 0.002018711995333433,\n",
       " 0.002070760354399681,\n",
       " 0.0020224968902766705,\n",
       " 0.002016067272052169,\n",
       " 0.0019883618224412203,\n",
       " 0.0020286415237933397,\n",
       " 0.002170438878238201,\n",
       " 0.0021362893749028444,\n",
       " 0.0020761422347277403,\n",
       " 0.002142682671546936,\n",
       " 0.002022983506321907,\n",
       " 0.0021386160515248775,\n",
       " 0.0021185355726629496,\n",
       " 0.0021849912591278553,\n",
       " 0.0022042880300432444,\n",
       " 0.0021731622982770205,\n",
       " 0.0020674834959208965,\n",
       " 0.002047557383775711,\n",
       " 0.0020708569791167974,\n",
       " 0.0020310450345277786,\n",
       " 0.0021293447352945805,\n",
       " 0.002026425441727042,\n",
       " 0.0020504400599747896,\n",
       " 0.0020674625411629677,\n",
       " 0.0020236074924468994,\n",
       " 0.0023356731981039047,\n",
       " 0.002362827304750681,\n",
       " 0.002472599968314171,\n",
       " 0.0027495338581502438,\n",
       " 0.0025699955876916647,\n",
       " 0.002330255229026079,\n",
       " 0.0023231052327901125,\n",
       " 0.002404827158898115,\n",
       " 0.0027977842837572098,\n",
       " 0.002411110559478402,\n",
       " 0.0022767672780901194,\n",
       " 0.0025279144756495953,\n",
       " 0.00253128819167614,\n",
       " 0.002461796160787344,\n",
       " 0.002227633725851774,\n",
       " 0.0023021488450467587,\n",
       " 0.002604602836072445,\n",
       " 0.002272251760587096,\n",
       " 0.002192987594753504,\n",
       " 0.0022121393121778965,\n",
       " 0.0023495336063206196,\n",
       " 0.0022794841788709164,\n",
       " 0.0021373587660491467,\n",
       " 0.0022989180870354176,\n",
       " 0.002116826828569174,\n",
       " 0.00212905858643353,\n",
       " 0.0020693771075457335,\n",
       " 0.002243188675493002,\n",
       " 0.0023337851744145155,\n",
       " 0.002065175911411643,\n",
       " 0.0021432824432849884,\n",
       " 0.0022007483057677746,\n",
       " 0.00226121349260211,\n",
       " 0.00215124967508018,\n",
       " 0.002058032900094986,\n",
       " 0.002162784803658724,\n",
       " 0.0020520046819001436,\n",
       " 0.002030691597610712,\n",
       " 0.002112237736582756,\n",
       " 0.002082512713968754,\n",
       " 0.0020468803122639656,\n",
       " 0.0020600412972271442,\n",
       " 0.002070825779810548,\n",
       " 0.0020740192849189043,\n",
       " 0.0019819329027086496,\n",
       " 0.0020648417994379997,\n",
       " 0.00201447494328022,\n",
       " 0.00200865906663239,\n",
       " 0.002065332606434822,\n",
       " 0.002001067390665412,\n",
       " 0.001959698973223567,\n",
       " 0.002070118673145771,\n",
       " 0.0020655891858041286,\n",
       " 0.0021761825773864985,\n",
       " 0.002092742593958974,\n",
       " 0.0019937411416321993,\n",
       " 0.0020569325424730778,\n",
       " 0.001958089414983988,\n",
       " 0.00199621613137424,\n",
       " 0.001968111377209425,\n",
       " 0.0019173515029251575,\n",
       " 0.0020887721329927444,\n",
       " 0.002100598532706499,\n",
       " 0.0021448249462991953,\n",
       " 0.002026875503361225,\n",
       " 0.001973428763449192,\n",
       " 0.002094581723213196,\n",
       " 0.0020649870857596397,\n",
       " 0.00203948887065053,\n",
       " 0.002118581673130393,\n",
       " 0.0020730493124574423,\n",
       " 0.0020047968719154596,\n",
       " 0.0022209901362657547,\n",
       " 0.00211983360350132,\n",
       " 0.001976786646991968,\n",
       " 0.00225449469871819,\n",
       " 0.0021347436122596264,\n",
       " 0.0021169655956327915,\n",
       " 0.0022836069110780954,\n",
       " 0.002079616067931056,\n",
       " 0.0020921106915920973,\n",
       " 0.00221580034121871,\n",
       " 0.0020951295737177134,\n",
       " 0.0021517490968108177,\n",
       " 0.002301743719726801,\n",
       " 0.002230602316558361,\n",
       " 0.0022301371209323406,\n",
       " 0.0020365293603390455,\n",
       " 0.002072632312774658,\n",
       " 0.0021571239922195673,\n",
       " 0.0020632222294807434,\n",
       " 0.0021966644562780857,\n",
       " 0.0021841609850525856,\n",
       " 0.002020410029217601,\n",
       " 0.002190523548051715,\n",
       " 0.0022153793834149837,\n",
       " 0.002340273931622505,\n",
       " 0.002166498452425003,\n",
       " 0.0020569581538438797,\n",
       " 0.002096117939800024,\n",
       " 0.0022780466824769974,\n",
       " 0.002218790352344513,\n",
       " 0.0021904343739151955,\n",
       " 0.0020257418509572744,\n",
       " 0.002430845983326435,\n",
       " 0.002323310589417815,\n",
       " 0.0022377732675522566,\n",
       " 0.002320143161341548,\n",
       " 0.0022995183244347572,\n",
       " 0.0025175833143293858,\n",
       " 0.00215101963840425,\n",
       " 0.0020039877854287624,\n",
       " 0.002271563047543168,\n",
       " 0.0021690942812711,\n",
       " 0.0022653581108897924,\n",
       " 0.002221042988821864,\n",
       " 0.002009740797802806,\n",
       " 0.002279892796650529,\n",
       " 0.0021450468339025974,\n",
       " 0.0022395686246454716,\n",
       " 0.002185199409723282,\n",
       " 0.0020259739831089973,\n",
       " 0.0021424423903226852,\n",
       " 0.001995907397940755,\n",
       " 0.0021490934304893017,\n",
       " 0.002171801868826151,\n",
       " 0.0019629988819360733,\n",
       " 0.002154441550374031,\n",
       " 0.002105003222823143,\n",
       " 0.002106280066072941,\n",
       " 0.0020469760056585073,\n",
       " 0.002135429298505187,\n",
       " 0.0020891642197966576,\n",
       " 0.0019887788221240044,\n",
       " 0.0019727451726794243,\n",
       " 0.0020394278690218925,\n",
       " 0.0020904054399579763,\n",
       " 0.0019762013107538223,\n",
       " 0.002050659852102399,\n",
       " 0.002002499531954527,\n",
       " 0.0020227713976055384,\n",
       " 0.0020225851330906153,\n",
       " 0.0020639272406697273,\n",
       " 0.0019577560015022755,\n",
       " 0.0019884584471583366,\n",
       " 0.0020585607271641493,\n",
       " 0.0020708362571895123,\n",
       " 0.002128198044374585,\n",
       " 0.0020410013385117054,\n",
       " 0.0020528840832412243,\n",
       " 0.0022582439705729485,\n",
       " 0.0020574494265019894,\n",
       " 0.002041423926129937,\n",
       " 0.0020092749036848545,\n",
       " 0.002059465041384101,\n",
       " 0.00201052357442677,\n",
       " 0.001974803628399968,\n",
       " 0.0020164705347269773,\n",
       " 0.002037969883531332,\n",
       " 0.002113834721967578,\n",
       " 0.0021599801257252693,\n",
       " 0.0021086905617266893,\n",
       " 0.002038217382505536,\n",
       " 0.0020721990149468184,\n",
       " 0.0020847462583333254,\n",
       " 0.002085112500935793,\n",
       " 0.0020477473735809326,\n",
       " 0.00222592381760478,\n",
       " 0.00246842741034925,\n",
       " 0.0024771038442850113,\n",
       " 0.0023252805694937706,\n",
       " 0.0021625361405313015,\n",
       " 0.0023840211797505617,\n",
       " 0.002434193855151534,\n",
       " 0.002345760352909565,\n",
       " 0.0021433490328490734,\n",
       " 0.002511335304006934,\n",
       " 0.0026962733827531338,\n",
       " 0.0022164476104080677,\n",
       " 0.002344540785998106,\n",
       " 0.0024800896644592285,\n",
       " 0.00224347529001534,\n",
       " 0.0025580478832125664,\n",
       " 0.002556568942964077,\n",
       " 0.0021402325946837664,\n",
       " 0.0022824457846581936,\n",
       " 0.002597362268716097,\n",
       " 0.002188652753829956,\n",
       " 0.002236192114651203,\n",
       " 0.0023385847453027964,\n",
       " 0.0020943533163517714,\n",
       " 0.0024135715793818235,\n",
       " 0.0024801180697977543,\n",
       " 0.00228437059558928,\n",
       " 0.002455434761941433,\n",
       " 0.002648217137902975,\n",
       " 0.0021416638046503067,\n",
       " 0.00290567334741354,\n",
       " 0.0028394078835844994,\n",
       " 0.002277256455272436,\n",
       " 0.0038908165879547596,\n",
       " 0.003641418879851699,\n",
       " 0.0028805569745600224,\n",
       " 0.004993760492652655,\n",
       " 0.003885428886860609,\n",
       " 0.0033890781924128532,\n",
       " 0.004443850368261337,\n",
       " 0.0025802692398428917,\n",
       " 0.002965081948786974,\n",
       " 0.0029286143835633993,\n",
       " 0.0025259582325816154,\n",
       " 0.0027358192019164562,\n",
       " 0.0021810419857501984,\n",
       " 0.003085092641413212,\n",
       " 0.0023695258423686028,\n",
       " 0.0023425696417689323,\n",
       " 0.0024821117985993624,\n",
       " 0.002319185994565487,\n",
       " 0.0023417880292981863,\n",
       " 0.0022227508015930653,\n",
       " 0.002644098363816738,\n",
       " 0.002155901864171028,\n",
       " 0.002125919796526432,\n",
       " 0.0022769328206777573,\n",
       " 0.0020656760316342115,\n",
       " 0.00219364813528955,\n",
       " 0.0020920864772051573,\n",
       " 0.0022245198488235474,\n",
       " 0.0019831776153296232,\n",
       " 0.0020620899740606546,\n",
       " 0.0022649262100458145,\n",
       " 0.002030049916356802,\n",
       " 0.002071022056043148,\n",
       " 0.002106602070853114,\n",
       " 0.0020639155991375446,\n",
       " 0.0020584187004715204,\n",
       " 0.0020311460830271244,\n",
       " 0.0021447413600981236,\n",
       " 0.0019668254535645247,\n",
       " 0.0020008422434329987,\n",
       " 0.002028088551014662,\n",
       " 0.0019954098388552666,\n",
       " 0.0019738636910915375,\n",
       " 0.0020237118005752563,\n",
       " 0.002052015857771039,\n",
       " 0.001955544576048851,\n",
       " 0.0020479389932006598,\n",
       " 0.002017850521951914,\n",
       " 0.0019665989093482494,\n",
       " 0.002011023461818695,\n",
       " 0.002021981403231621,\n",
       " 0.001992227975279093,\n",
       " 0.002015667036175728,\n",
       " 0.0020136565435677767,\n",
       " 0.002010759897530079,\n",
       " 0.00198608567006886,\n",
       " 0.002059035003185272,\n",
       " 0.0019994170870631933,\n",
       " 0.0020039277151226997,\n",
       " 0.0020182207226753235,\n",
       " 0.0020909046288579702,\n",
       " 0.002015962265431881,\n",
       " 0.0019348578061908484,\n",
       " 0.001978137530386448,\n",
       " 0.0019263513386249542,\n",
       " 0.0019604088738560677,\n",
       " 0.001963317394256592,\n",
       " 0.001979600405320525,\n",
       " 0.0019530170829966664,\n",
       " 0.0020107890013605356,\n",
       " 0.002015095902606845,\n",
       " 0.0019584940746426582,\n",
       " 0.001962426584213972,\n",
       " 0.001978284912183881,\n",
       " 0.0019984710961580276,\n",
       " 0.0020053645130246878,\n",
       " 0.0019425228238105774,\n",
       " 0.002005685120820999,\n",
       " 0.0020012003369629383,\n",
       " 0.0020033661276102066,\n",
       " 0.001998896710574627,\n",
       " 0.0019878128077834845,\n",
       " 0.001969900680705905,\n",
       " 0.001946010161191225,\n",
       " 0.0020600552670657635,\n",
       " 0.0020392760634422302,\n",
       " 0.002001076238229871]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of optimization steps\n",
    "Niter = 1000\n",
    "# Weight for the chamfer loss\n",
    "w_chamfer = 1.0 \n",
    "# Weight for mesh edge loss\n",
    "w_edge = 1.0 \n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 0.01 \n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 0.1 \n",
    "# Plot period for the losses\n",
    "plot_period = 250\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "chamfer_losses = []\n",
    "laplacian_losses = []\n",
    "edge_losses = []\n",
    "normal_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    v, _ = cube()\n",
    "    # Deform the mesh\n",
    "    new_src_mesh = src_mesh.offset_verts(v)\n",
    "    \n",
    "    # We sample 5k points from the surface of each mesh \n",
    "    sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
    "    sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
    "    \n",
    "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
    "    loss_chamfer, _ = chamfer_distance(sample_trg, sample_src)\n",
    "    \n",
    "    #if False:\n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
    "\n",
    "    # mesh normal consistency\n",
    "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
    "\n",
    "    # mesh laplacian smoothing\n",
    "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
    "\n",
    "    # Weighted sum of the losses\n",
    "    loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    #loss = loss_chamfer\n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "#     edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "#     normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "#     laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    #if i % plot_period == 0:\n",
    "    #    plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "chamfer_losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29a627cda644eb990696d3b6cfffe82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0020848â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7fcc24ce5d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import meshplot\n",
    "\n",
    "vert =  start + v\n",
    "meshplot.plot(vert.detach().cpu().numpy(), f.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vert.cpu(), './data/sampled_32_32.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vertices(stacked):\n",
    "    return stacked.permute(0, 2, 3, 1).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.randn(6, 3, 8, 8)\n",
    "as_vs = to_vertices(s)\n",
    "as_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 8, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "f_n = int(math.sqrt(as_vs.size(0) // 6))\n",
    "f_n\n",
    "as_st = as_vs.reshape(6, f_n, f_n, 3).permute(0, 3, 1, 2)\n",
    "as_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(s, as_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cube.state_dict(), './data/net_fitted_32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (head): ConvBlock(\n",
       "    (conv): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): ConvBlock(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (block2): ConvBlock(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (block3): ConvBlock(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (tail): Sequential(\n",
       "    (0): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def to_stacked():\n",
    "f_n = int(math.sqrt(as_vs.size(0) // 6))\n",
    "f_n\n",
    "as_st = as_vs.reshape(6, f_n, f_n, 3).permute(0, 3, 1, 2)\n",
    "as_st.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conjure] *",
   "language": "python",
   "name": "conda-env-conjure-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.shared.wavelet import (\n",
    "    dwt, \n",
    "    iwt,\n",
    ")\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 48, 8, 8]), tensor(    0.0000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 32\n",
    "entry = torch.randn(6, 3, n, n)\n",
    "dwted =  dwt(dwt(entry))\n",
    "iwted = iwt(iwt(dwted))\n",
    "dwted.shape, (entry - iwted).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536, 3]) torch.Size([3068, 3])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'meshplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e255eaab96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmeshplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'meshplot' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from src.shared.faces import make_cube_faces\n",
    "from src.shared.sides import (    \n",
    "    to_vertices,\n",
    "    make_phi_theta,\n",
    "    sphered_vertices,\n",
    "    to_spherical,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class Coarse(nn.Module):\n",
    "    def __init__(self, n, r=0.5):\n",
    "        super(Coarse, self).__init__()        \n",
    "        self.n = n\n",
    "        phi, theta = make_phi_theta(n)\n",
    "        self.register_buffer('phi', phi)\n",
    "        self.register_buffer('theta', theta)\n",
    "        self.register_buffer('faces', make_cube_faces(n))                \n",
    "        self.register_buffer('sphere', to_spherical(sphered_vertices(n, r)))\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3, 32, 3, padding=1, padding_mode='reflect')),\n",
    "            ('relu1', nn.LeakyReLU(0.1)),\n",
    "            ('conv2', nn.Conv2d(32,3, 3, padding=1, padding_mode='reflect')),\n",
    "            ('relu2', nn.Sigmoid())\n",
    "        ]))\n",
    "        self.radii = torch.nn.Parameter(torch.zeros(3, *phi.shape))    \n",
    "   \n",
    "    def get_ellipsoidal(self, radii):\n",
    "        x = radii[:, 0, :, :] * torch.sin(self.theta) * torch.cos(self.phi)\n",
    "        y = radii[:, 1, :, :] * torch.sin(self.theta) * torch.sin(self.phi)\n",
    "        z = radii[:, 2, :, :] * torch.cos(self.theta) \n",
    "        return torch.stack((x, y, z), dim=1)   \n",
    "    \n",
    "    def forward(self):        \n",
    "        radii = self.net(self.sphere) +0.5\n",
    "        ellipsoidal = self.get_ellipsoidal(radii) + self.sphere\n",
    "        vert = to_vertices(ellipsoidal)\n",
    "        return vert, self.faces\n",
    "n = 16\n",
    "coarse = Coarse(n)\n",
    "\n",
    "v, f = coarse()\n",
    "print(v.shape, f.shape)\n",
    "\n",
    "\n",
    "meshplot.plot(v.detach().numpy(), f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b5c3fc5a004cbebc5452127eb9ca83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.566085â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7fe27073e350>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import meshplot\n",
    "\n",
    "meshplot.plot(v.detach().numpy(), f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5821, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(4, 4).cuda()\n",
    "t.requires_grad_(True)\n",
    "\n",
    "optimizer = torch.optim.Adam([t], lr=0.01)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7088, -0.7346,  0.8056, -0.2323],\n",
      "        [ 0.7319, -0.3856, -0.7708, -1.6826],\n",
      "        [ 1.6372,  0.3474, -0.2518,  0.5446],\n",
      "        [-1.6594,  0.9039, -0.8347, -0.4844]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "0 0.7947365045547485\n",
      "1 0.7847365140914917\n",
      "2 0.7747365236282349\n",
      "3 0.764736533164978\n",
      "4 0.7547365427017212\n",
      "5 0.7261481285095215\n",
      "6 0.7167730927467346\n",
      "7 0.7073980569839478\n",
      "8 0.6980230808258057\n",
      "9 0.6886481046676636\n",
      "10 0.6792731285095215\n",
      "11 0.6698981523513794\n",
      "12 0.6605231761932373\n",
      "13 0.6511481404304504\n",
      "14 0.6360033750534058\n",
      "15 0.6272534132003784\n",
      "16 0.6127679347991943\n",
      "17 0.6046428680419922\n",
      "18 0.5965179204940796\n",
      "19 0.588392972946167\n",
      "20 0.5802679061889648\n",
      "21 0.5721429586410522\n",
      "22 0.5640179514884949\n",
      "23 0.5558929443359375\n",
      "24 0.5477679967880249\n",
      "25 0.5212278366088867\n",
      "26 0.5137278437614441\n",
      "27 0.5062278509140015\n",
      "28 0.49872785806655884\n",
      "29 0.4852498173713684\n",
      "30 0.4783748388290405\n",
      "31 0.47149980068206787\n",
      "32 0.46462482213974\n",
      "33 0.4577498435974121\n",
      "34 0.45087486505508423\n",
      "35 0.4439998269081116\n",
      "36 0.4371248483657837\n",
      "37 0.4302498698234558\n",
      "38 0.42337489128112793\n",
      "39 0.41059958934783936\n",
      "40 0.40434956550598145\n",
      "41 0.3980996012687683\n",
      "42 0.3918495774269104\n",
      "43 0.38559961318969727\n",
      "44 0.36110395193099976\n",
      "45 0.3554789423942566\n",
      "46 0.3498539626598358\n",
      "47 0.34422898292541504\n",
      "48 0.3386039733886719\n",
      "49 0.3329789638519287\n",
      "50 0.32735398411750793\n",
      "51 0.30325454473495483\n",
      "52 0.2982545495033264\n",
      "53 0.293254554271698\n",
      "54 0.2882545590400696\n",
      "55 0.28325456380844116\n",
      "56 0.27825456857681274\n",
      "57 0.2732545733451843\n",
      "58 0.2682545781135559\n",
      "59 0.2632545828819275\n",
      "60 0.2582545876502991\n",
      "61 0.22871489822864532\n",
      "62 0.2249649167060852\n",
      "63 0.2212149053812027\n",
      "64 0.21155156195163727\n",
      "65 0.2084265500307083\n",
      "66 0.20530156791210175\n",
      "67 0.2021765559911728\n",
      "68 0.19337482750415802\n",
      "69 0.1908748298883438\n",
      "70 0.1883748322725296\n",
      "71 0.1858748346567154\n",
      "72 0.18337483704090118\n",
      "73 0.18087483942508698\n",
      "74 0.17245548963546753\n",
      "75 0.17058050632476807\n",
      "76 0.16870549321174622\n",
      "77 0.16683050990104675\n",
      "78 0.1649554967880249\n",
      "79 0.16308051347732544\n",
      "80 0.1612055003643036\n",
      "81 0.15933051705360413\n",
      "82 0.15745550394058228\n",
      "83 0.1555805206298828\n",
      "84 0.15370550751686096\n",
      "85 0.1518305242061615\n",
      "86 0.14995551109313965\n",
      "87 0.14808052778244019\n",
      "88 0.14620551466941833\n",
      "89 0.14433053135871887\n",
      "90 0.14245551824569702\n",
      "91 0.14058053493499756\n",
      "92 0.1387055218219757\n",
      "93 0.13683053851127625\n",
      "94 0.1349555253982544\n",
      "95 0.13308054208755493\n",
      "96 0.13120552897453308\n",
      "97 0.12933054566383362\n",
      "98 0.12745553255081177\n",
      "99 0.1255805492401123\n",
      "100 0.12370554357767105\n",
      "101 0.1218305453658104\n",
      "102 0.11995554715394974\n",
      "103 0.11808054894208908\n",
      "104 0.11620555073022842\n",
      "105 0.11433055251836777\n",
      "106 0.11245555430650711\n",
      "107 0.11058055609464645\n",
      "108 0.1087055578827858\n",
      "109 0.10683055967092514\n",
      "110 0.10495556145906448\n",
      "111 0.10308056324720383\n",
      "112 0.10120556503534317\n",
      "113 0.09933056682348251\n",
      "114 0.09745556861162186\n",
      "115 0.0955805703997612\n",
      "116 0.09370557218790054\n",
      "117 0.09183057397603989\n",
      "118 0.08995557576417923\n",
      "119 0.08808057755231857\n",
      "120 0.08620557934045792\n",
      "121 0.08433058112859726\n",
      "122 0.0824555829167366\n",
      "123 0.08058058470487595\n",
      "124 0.07870558649301529\n",
      "125 0.07683058828115463\n",
      "126 0.07495559006929398\n",
      "127 0.07308059185743332\n",
      "128 0.07120559364557266\n",
      "129 0.069330595433712\n",
      "130 0.06745559722185135\n",
      "131 0.06558059900999069\n",
      "132 0.06370560079813004\n",
      "133 0.06183060258626938\n",
      "134 0.04138006269931793\n",
      "135 0.04013006389141083\n",
      "136 0.03888006508350372\n",
      "137 0.03763006627559662\n",
      "138 0.036380067467689514\n",
      "139 0.03513006865978241\n",
      "140 0.033880069851875305\n",
      "141 0.0326300710439682\n",
      "142 0.031380072236061096\n",
      "143 0.03013007342815399\n",
      "144 0.028880074620246887\n",
      "145 0.027630075812339783\n",
      "146 0.026380077004432678\n",
      "147 0.025130078196525574\n",
      "148 0.02388007938861847\n",
      "149 0.022630080580711365\n",
      "150 0.02138008177280426\n",
      "151 0.020130082964897156\n",
      "152 0.01888008415699005\n",
      "153 0.017630085349082947\n",
      "154 0.016380086541175842\n",
      "155 0.015130088664591312\n",
      "156 0.007665127981454134\n",
      "157 0.007040129043161869\n",
      "158 0.006415130104869604\n",
      "159 0.0\n",
      "160 0.0\n",
      "161 0.0\n",
      "162 0.0\n",
      "163 0.0\n",
      "164 0.0\n",
      "165 0.0\n",
      "166 0.0\n",
      "167 0.0\n",
      "168 0.0\n",
      "169 0.0\n",
      "170 0.0\n",
      "171 0.0\n",
      "172 0.0\n",
      "173 0.0\n",
      "174 0.0\n",
      "175 0.0\n",
      "176 0.0\n",
      "177 0.0\n",
      "178 0.0\n",
      "179 0.0\n",
      "180 0.0\n",
      "181 0.0\n",
      "182 0.0\n",
      "183 0.0\n",
      "184 0.0\n",
      "185 0.0\n",
      "186 0.0\n",
      "187 0.0\n",
      "188 0.0\n",
      "189 0.0\n",
      "190 0.0\n",
      "191 0.0\n",
      "192 0.0\n",
      "193 0.0\n",
      "194 0.0\n",
      "195 0.0\n",
      "196 0.0\n",
      "197 0.0\n",
      "198 0.0\n",
      "199 0.0\n",
      "200 0.0\n",
      "201 0.0\n",
      "202 0.0\n",
      "203 0.0\n",
      "204 0.0\n",
      "205 0.0\n",
      "206 0.0\n",
      "207 0.0\n",
      "208 0.0\n",
      "209 0.0\n",
      "210 0.0\n",
      "211 0.0\n",
      "212 0.0\n",
      "213 0.0\n",
      "214 0.0\n",
      "215 0.0\n",
      "216 0.0\n",
      "217 0.0\n",
      "218 0.0\n",
      "219 0.0\n",
      "220 0.0\n",
      "221 0.0\n",
      "222 0.0\n",
      "223 0.0\n",
      "224 0.0\n",
      "225 0.0\n",
      "226 0.0\n",
      "227 0.0\n",
      "228 0.0\n",
      "229 0.0\n",
      "230 0.0\n",
      "231 0.0\n",
      "232 0.0\n",
      "233 0.0\n",
      "234 0.0\n",
      "235 0.0\n",
      "236 0.0\n",
      "237 0.0\n",
      "238 0.0\n",
      "239 0.0\n",
      "240 0.0\n",
      "241 0.0\n",
      "242 0.0\n",
      "243 0.0\n",
      "244 0.0\n",
      "245 0.0\n",
      "246 0.0\n",
      "247 0.0\n",
      "248 0.0\n",
      "249 0.0\n",
      "250 0.0\n",
      "251 0.0\n",
      "252 0.0\n",
      "253 0.0\n",
      "254 0.0\n",
      "255 0.0\n",
      "256 0.0\n",
      "257 0.0\n",
      "258 0.0\n",
      "259 0.0\n",
      "260 0.0\n",
      "261 0.0\n",
      "262 0.0\n",
      "263 0.0\n",
      "264 0.0\n",
      "265 0.0\n",
      "266 0.0\n",
      "267 0.0\n",
      "268 0.0\n",
      "269 0.0\n",
      "270 0.0\n",
      "271 0.0\n",
      "272 0.0\n",
      "273 0.0\n",
      "274 0.0\n",
      "275 0.0\n",
      "276 0.0\n",
      "277 0.0\n",
      "278 0.0\n",
      "279 0.0\n",
      "280 0.0\n",
      "281 0.0\n",
      "282 0.0\n",
      "283 0.0\n",
      "284 0.0\n",
      "285 0.0\n",
      "286 0.0\n",
      "287 0.0\n",
      "288 0.0\n",
      "289 0.0\n",
      "290 0.0\n",
      "291 0.0\n",
      "292 0.0\n",
      "293 0.0\n",
      "294 0.0\n",
      "295 0.0\n",
      "296 0.0\n",
      "297 0.0\n",
      "298 0.0\n",
      "299 0.0\n",
      "300 0.0\n",
      "301 0.0\n",
      "302 0.0\n",
      "303 0.0\n",
      "304 0.0\n",
      "305 0.0\n",
      "306 0.0\n",
      "307 0.0\n",
      "308 0.0\n",
      "309 0.0\n",
      "310 0.0\n",
      "311 0.0\n",
      "312 0.0\n",
      "313 0.0\n",
      "314 0.0\n",
      "315 0.0\n",
      "316 0.0\n",
      "317 0.0\n",
      "318 0.0\n",
      "319 0.0\n",
      "320 0.0\n",
      "321 0.0\n",
      "322 0.0\n",
      "323 0.0\n",
      "324 0.0\n",
      "325 0.0\n",
      "326 0.0\n",
      "327 0.0\n",
      "328 0.0\n",
      "329 0.0\n",
      "330 0.0\n",
      "331 0.0\n",
      "332 0.0\n",
      "333 0.0\n",
      "334 0.0\n",
      "335 0.0\n",
      "336 0.0\n",
      "337 0.0\n",
      "338 0.0\n",
      "339 0.0\n",
      "340 0.0\n",
      "341 0.0\n",
      "342 0.0\n",
      "343 0.0\n",
      "344 0.0\n",
      "345 0.0\n",
      "346 0.0\n",
      "347 0.0\n",
      "348 0.0\n",
      "349 0.0\n",
      "350 0.0\n",
      "351 0.0\n",
      "352 0.0\n",
      "353 0.0\n",
      "354 0.0\n",
      "355 0.0\n",
      "356 0.0\n",
      "357 0.0\n",
      "358 0.0\n",
      "359 0.0\n",
      "360 0.0\n",
      "361 0.0\n",
      "362 0.0\n",
      "363 0.0\n",
      "364 0.0\n",
      "365 0.0\n",
      "366 0.0\n",
      "367 0.0\n",
      "368 0.0\n",
      "369 0.0\n",
      "370 0.0\n",
      "371 0.0\n",
      "372 0.0\n",
      "373 0.0\n",
      "374 0.0\n",
      "375 0.0\n",
      "376 0.0\n",
      "377 0.0\n",
      "378 0.0\n",
      "379 0.0\n",
      "380 0.0\n",
      "381 0.0\n",
      "382 0.0\n",
      "383 0.0\n",
      "384 0.0\n",
      "385 0.0\n",
      "386 0.0\n",
      "387 0.0\n",
      "388 0.0\n",
      "389 0.0\n",
      "390 0.0\n",
      "391 0.0\n",
      "392 0.0\n",
      "393 0.0\n",
      "394 0.0\n",
      "395 0.0\n",
      "396 0.0\n",
      "397 0.0\n",
      "398 0.0\n",
      "399 0.0\n",
      "400 0.0\n",
      "401 0.0\n",
      "402 0.0\n",
      "403 0.0\n",
      "404 0.0\n",
      "405 0.0\n",
      "406 0.0\n",
      "407 0.0\n",
      "408 0.0\n",
      "409 0.0\n",
      "410 0.0\n",
      "411 0.0\n",
      "412 0.0\n",
      "413 0.0\n",
      "414 0.0\n",
      "415 0.0\n",
      "416 0.0\n",
      "417 0.0\n",
      "418 0.0\n",
      "419 0.0\n",
      "420 0.0\n",
      "421 0.0\n",
      "422 0.0\n",
      "423 0.0\n",
      "424 0.0\n",
      "425 0.0\n",
      "426 0.0\n",
      "427 0.0\n",
      "428 0.0\n",
      "429 0.0\n",
      "430 0.0\n",
      "431 0.0\n",
      "432 0.0\n",
      "433 0.0\n",
      "434 0.0\n",
      "435 0.0\n",
      "436 0.0\n",
      "437 0.0\n",
      "438 0.0\n",
      "439 0.0\n",
      "440 0.0\n",
      "441 0.0\n",
      "442 0.0\n",
      "443 0.0\n",
      "444 0.0\n",
      "445 0.0\n",
      "446 0.0\n",
      "447 0.0\n",
      "448 0.0\n",
      "449 0.0\n",
      "450 0.0\n",
      "451 0.0\n",
      "452 0.0\n",
      "453 0.0\n",
      "454 0.0\n",
      "455 0.0\n",
      "456 0.0\n",
      "457 0.0\n",
      "458 0.0\n",
      "459 0.0\n",
      "460 0.0\n",
      "461 0.0\n",
      "462 0.0\n",
      "463 0.0\n",
      "464 0.0\n",
      "465 0.0\n",
      "466 0.0\n",
      "467 0.0\n",
      "468 0.0\n",
      "469 0.0\n",
      "470 0.0\n",
      "471 0.0\n",
      "472 0.0\n",
      "473 0.0\n",
      "474 0.0\n",
      "475 0.0\n",
      "476 0.0\n",
      "477 0.0\n",
      "478 0.0\n",
      "479 0.0\n",
      "480 0.0\n",
      "481 0.0\n",
      "482 0.0\n",
      "483 0.0\n",
      "484 0.0\n",
      "485 0.0\n",
      "486 0.0\n",
      "487 0.0\n",
      "488 0.0\n",
      "489 0.0\n",
      "490 0.0\n",
      "491 0.0\n",
      "492 0.0\n",
      "493 0.0\n",
      "494 0.0\n",
      "495 0.0\n",
      "496 0.0\n",
      "497 0.0\n",
      "498 0.0\n",
      "499 0.0\n",
      "500 0.0\n",
      "501 0.0\n",
      "502 0.0\n",
      "503 0.0\n",
      "504 0.0\n",
      "505 0.0\n",
      "506 0.0\n",
      "507 0.0\n",
      "508 0.0\n",
      "509 0.0\n",
      "510 0.0\n",
      "511 0.0\n",
      "512 0.0\n",
      "513 0.0\n",
      "514 0.0\n",
      "515 0.0\n",
      "516 0.0\n",
      "517 0.0\n",
      "518 0.0\n",
      "519 0.0\n",
      "520 0.0\n",
      "521 0.0\n",
      "522 0.0\n",
      "523 0.0\n",
      "524 0.0\n",
      "525 0.0\n",
      "526 0.0\n",
      "527 0.0\n",
      "528 0.0\n",
      "529 0.0\n",
      "530 0.0\n",
      "531 0.0\n",
      "532 0.0\n",
      "533 0.0\n",
      "534 0.0\n",
      "535 0.0\n",
      "536 0.0\n",
      "537 0.0\n",
      "538 0.0\n",
      "539 0.0\n",
      "540 0.0\n",
      "541 0.0\n",
      "542 0.0\n",
      "543 0.0\n",
      "544 0.0\n",
      "545 0.0\n",
      "546 0.0\n",
      "547 0.0\n",
      "548 0.0\n",
      "549 0.0\n",
      "550 0.0\n",
      "551 0.0\n",
      "552 0.0\n",
      "553 0.0\n",
      "554 0.0\n",
      "555 0.0\n",
      "556 0.0\n",
      "557 0.0\n",
      "558 0.0\n",
      "559 0.0\n",
      "560 0.0\n",
      "561 0.0\n",
      "562 0.0\n",
      "563 0.0\n",
      "564 0.0\n",
      "565 0.0\n",
      "566 0.0\n",
      "567 0.0\n",
      "568 0.0\n",
      "569 0.0\n",
      "570 0.0\n",
      "571 0.0\n",
      "572 0.0\n",
      "573 0.0\n",
      "574 0.0\n",
      "575 0.0\n",
      "576 0.0\n",
      "577 0.0\n",
      "578 0.0\n",
      "579 0.0\n",
      "580 0.0\n",
      "581 0.0\n",
      "582 0.0\n",
      "583 0.0\n",
      "584 0.0\n",
      "585 0.0\n",
      "586 0.0\n",
      "587 0.0\n",
      "588 0.0\n",
      "589 0.0\n",
      "590 0.0\n",
      "591 0.0\n",
      "592 0.0\n",
      "593 0.0\n",
      "594 0.0\n",
      "595 0.0\n",
      "596 0.0\n",
      "597 0.0\n",
      "598 0.0\n",
      "599 0.0\n",
      "600 0.0\n",
      "601 0.0\n",
      "602 0.0\n",
      "603 0.0\n",
      "604 0.0\n",
      "605 0.0\n",
      "606 0.0\n",
      "607 0.0\n",
      "608 0.0\n",
      "609 0.0\n",
      "610 0.0\n",
      "611 0.0\n",
      "612 0.0\n",
      "613 0.0\n",
      "614 0.0\n",
      "615 0.0\n",
      "616 0.0\n",
      "617 0.0\n",
      "618 0.0\n",
      "619 0.0\n",
      "620 0.0\n",
      "621 0.0\n",
      "622 0.0\n",
      "623 0.0\n",
      "624 0.0\n",
      "625 0.0\n",
      "626 0.0\n",
      "627 0.0\n",
      "628 0.0\n",
      "629 0.0\n",
      "630 0.0\n",
      "631 0.0\n",
      "632 0.0\n",
      "633 0.0\n",
      "634 0.0\n",
      "635 0.0\n",
      "636 0.0\n",
      "637 0.0\n",
      "638 0.0\n",
      "639 0.0\n",
      "640 0.0\n",
      "641 0.0\n",
      "642 0.0\n",
      "643 0.0\n",
      "644 0.0\n",
      "645 0.0\n",
      "646 0.0\n",
      "647 0.0\n",
      "648 0.0\n",
      "649 0.0\n",
      "650 0.0\n",
      "651 0.0\n",
      "652 0.0\n",
      "653 0.0\n",
      "654 0.0\n",
      "655 0.0\n",
      "656 0.0\n",
      "657 0.0\n",
      "658 0.0\n",
      "659 0.0\n",
      "660 0.0\n",
      "661 0.0\n",
      "662 0.0\n",
      "663 0.0\n",
      "664 0.0\n",
      "665 0.0\n",
      "666 0.0\n",
      "667 0.0\n",
      "668 0.0\n",
      "669 0.0\n",
      "670 0.0\n",
      "671 0.0\n",
      "672 0.0\n",
      "673 0.0\n",
      "674 0.0\n",
      "675 0.0\n",
      "676 0.0\n",
      "677 0.0\n",
      "678 0.0\n",
      "679 0.0\n",
      "680 0.0\n",
      "681 0.0\n",
      "682 0.0\n",
      "683 0.0\n",
      "684 0.0\n",
      "685 0.0\n",
      "686 0.0\n",
      "687 0.0\n",
      "688 0.0\n",
      "689 0.0\n",
      "690 0.0\n",
      "691 0.0\n",
      "692 0.0\n",
      "693 0.0\n",
      "694 0.0\n",
      "695 0.0\n",
      "696 0.0\n",
      "697 0.0\n",
      "698 0.0\n",
      "699 0.0\n",
      "700 0.0\n",
      "701 0.0\n",
      "702 0.0\n",
      "703 0.0\n",
      "704 0.0\n",
      "705 0.0\n",
      "706 0.0\n",
      "707 0.0\n",
      "708 0.0\n",
      "709 0.0\n",
      "710 0.0\n",
      "711 0.0\n",
      "712 0.0\n",
      "713 0.0\n",
      "714 0.0\n",
      "715 0.0\n",
      "716 0.0\n",
      "717 0.0\n",
      "718 0.0\n",
      "719 0.0\n",
      "720 0.0\n",
      "721 0.0\n",
      "722 0.0\n",
      "723 0.0\n",
      "724 0.0\n",
      "725 0.0\n",
      "726 0.0\n",
      "727 0.0\n",
      "728 0.0\n",
      "729 0.0\n",
      "730 0.0\n",
      "731 0.0\n",
      "732 0.0\n",
      "733 0.0\n",
      "734 0.0\n",
      "735 0.0\n",
      "736 0.0\n",
      "737 0.0\n",
      "738 0.0\n",
      "739 0.0\n",
      "740 0.0\n",
      "741 0.0\n",
      "742 0.0\n",
      "743 0.0\n",
      "744 0.0\n",
      "745 0.0\n",
      "746 0.0\n",
      "747 0.0\n",
      "748 0.0\n",
      "749 0.0\n",
      "750 0.0\n",
      "751 0.0\n",
      "752 0.0\n",
      "753 0.0\n",
      "754 0.0\n",
      "755 0.0\n",
      "756 0.0\n",
      "757 0.0\n",
      "758 0.0\n",
      "759 0.0\n",
      "760 0.0\n",
      "761 0.0\n",
      "762 0.0\n",
      "763 0.0\n",
      "764 0.0\n",
      "765 0.0\n",
      "766 0.0\n",
      "767 0.0\n",
      "768 0.0\n",
      "769 0.0\n",
      "770 0.0\n",
      "771 0.0\n",
      "772 0.0\n",
      "773 0.0\n",
      "774 0.0\n",
      "775 0.0\n",
      "776 0.0\n",
      "777 0.0\n",
      "778 0.0\n",
      "779 0.0\n",
      "780 0.0\n",
      "781 0.0\n",
      "782 0.0\n",
      "783 0.0\n",
      "784 0.0\n",
      "785 0.0\n",
      "786 0.0\n",
      "787 0.0\n",
      "788 0.0\n",
      "789 0.0\n",
      "790 0.0\n",
      "791 0.0\n",
      "792 0.0\n",
      "793 0.0\n",
      "794 0.0\n",
      "795 0.0\n",
      "796 0.0\n",
      "797 0.0\n",
      "798 0.0\n",
      "799 0.0\n",
      "800 0.0\n",
      "801 0.0\n",
      "802 0.0\n",
      "803 0.0\n",
      "804 0.0\n",
      "805 0.0\n",
      "806 0.0\n",
      "807 0.0\n",
      "808 0.0\n",
      "809 0.0\n",
      "810 0.0\n",
      "811 0.0\n",
      "812 0.0\n",
      "813 0.0\n",
      "814 0.0\n",
      "815 0.0\n",
      "816 0.0\n",
      "817 0.0\n",
      "818 0.0\n",
      "819 0.0\n",
      "820 0.0\n",
      "821 0.0\n",
      "822 0.0\n",
      "823 0.0\n",
      "824 0.0\n",
      "825 0.0\n",
      "826 0.0\n",
      "827 0.0\n",
      "828 0.0\n",
      "829 0.0\n",
      "830 0.0\n",
      "831 0.0\n",
      "832 0.0\n",
      "833 0.0\n",
      "834 0.0\n",
      "835 0.0\n",
      "836 0.0\n",
      "837 0.0\n",
      "838 0.0\n",
      "839 0.0\n",
      "840 0.0\n",
      "841 0.0\n",
      "842 0.0\n",
      "843 0.0\n",
      "844 0.0\n",
      "845 0.0\n",
      "846 0.0\n",
      "847 0.0\n",
      "848 0.0\n",
      "849 0.0\n",
      "850 0.0\n",
      "851 0.0\n",
      "852 0.0\n",
      "853 0.0\n",
      "854 0.0\n",
      "855 0.0\n",
      "856 0.0\n",
      "857 0.0\n",
      "858 0.0\n",
      "859 0.0\n",
      "860 0.0\n",
      "861 0.0\n",
      "862 0.0\n",
      "863 0.0\n",
      "864 0.0\n",
      "865 0.0\n",
      "866 0.0\n",
      "867 0.0\n",
      "868 0.0\n",
      "869 0.0\n",
      "870 0.0\n",
      "871 0.0\n",
      "872 0.0\n",
      "873 0.0\n",
      "874 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875 0.0\n",
      "876 0.0\n",
      "877 0.0\n",
      "878 0.0\n",
      "879 0.0\n",
      "880 0.0\n",
      "881 0.0\n",
      "882 0.0\n",
      "883 0.0\n",
      "884 0.0\n",
      "885 0.0\n",
      "886 0.0\n",
      "887 0.0\n",
      "888 0.0\n",
      "889 0.0\n",
      "890 0.0\n",
      "891 0.0\n",
      "892 0.0\n",
      "893 0.0\n",
      "894 0.0\n",
      "895 0.0\n",
      "896 0.0\n",
      "897 0.0\n",
      "898 0.0\n",
      "899 0.0\n",
      "900 0.0\n",
      "901 0.0\n",
      "902 0.0\n",
      "903 0.0\n",
      "904 0.0\n",
      "905 0.0\n",
      "906 0.0\n",
      "907 0.0\n",
      "908 0.0\n",
      "909 0.0\n",
      "910 0.0\n",
      "911 0.0\n",
      "912 0.0\n",
      "913 0.0\n",
      "914 0.0\n",
      "915 0.0\n",
      "916 0.0\n",
      "917 0.0\n",
      "918 0.0\n",
      "919 0.0\n",
      "920 0.0\n",
      "921 0.0\n",
      "922 0.0\n",
      "923 0.0\n",
      "924 0.0\n",
      "925 0.0\n",
      "926 0.0\n",
      "927 0.0\n",
      "928 0.0\n",
      "929 0.0\n",
      "930 0.0\n",
      "931 0.0\n",
      "932 0.0\n",
      "933 0.0\n",
      "934 0.0\n",
      "935 0.0\n",
      "936 0.0\n",
      "937 0.0\n",
      "938 0.0\n",
      "939 0.0\n",
      "940 0.0\n",
      "941 0.0\n",
      "942 0.0\n",
      "943 0.0\n",
      "944 0.0\n",
      "945 0.0\n",
      "946 0.0\n",
      "947 0.0\n",
      "948 0.0\n",
      "949 0.0\n",
      "950 0.0\n",
      "951 0.0\n",
      "952 0.0\n",
      "953 0.0\n",
      "954 0.0\n",
      "955 0.0\n",
      "956 0.0\n",
      "957 0.0\n",
      "958 0.0\n",
      "959 0.0\n",
      "960 0.0\n",
      "961 0.0\n",
      "962 0.0\n",
      "963 0.0\n",
      "964 0.0\n",
      "965 0.0\n",
      "966 0.0\n",
      "967 0.0\n",
      "968 0.0\n",
      "969 0.0\n",
      "970 0.0\n",
      "971 0.0\n",
      "972 0.0\n",
      "973 0.0\n",
      "974 0.0\n",
      "975 0.0\n",
      "976 0.0\n",
      "977 0.0\n",
      "978 0.0\n",
      "979 0.0\n",
      "980 0.0\n",
      "981 0.0\n",
      "982 0.0\n",
      "983 0.0\n",
      "984 0.0\n",
      "985 0.0\n",
      "986 0.0\n",
      "987 0.0\n",
      "988 0.0\n",
      "989 0.0\n",
      "990 0.0\n",
      "991 0.0\n",
      "992 0.0\n",
      "993 0.0\n",
      "994 0.0\n",
      "995 0.0\n",
      "996 0.0\n",
      "997 0.0\n",
      "998 0.0\n",
      "999 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7071,  0.7368, -0.6082,  0.2399],\n",
       "        [-0.5391,  0.3912,  0.7764,  1.6830],\n",
       "        [-1.4335, -0.1346,  0.2608, -0.3516],\n",
       "        [ 1.6530, -0.7071,  0.8360,  0.4898]], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outside_bound(x, minima, maxima):\n",
    "    mx = torch.tensor(maxima).cuda()\n",
    "    mi = torch.tensor(minima).cuda()\n",
    "    mx_mask =  torch.where(x > mx, 1., 0.).detach()\n",
    "    mi_mask =  torch.where(x < mi, 1., 0.).detach()\n",
    "    mask = mi_mask + mx_mask\n",
    "    return (x * mask).abs().mean()\n",
    "\n",
    "start = t.detach().clone()\n",
    "print(t)\n",
    "for step in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = outside_bound(t, -0.1, 0.3)    \n",
    "    loss.backward()\n",
    "    print(step, loss.item())\n",
    "    optimizer.step()    \n",
    "t-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4747, 0.8223, 0.4925, 0.4389],\n",
       "        [0.1561, 0.4197, 0.0000, 0.7334],\n",
       "        [0.5435, 0.5205, 0.5587, 0.8802],\n",
       "        [0.9137, 0.8416, 0.8931, 0.5579]], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.abs() - t.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0495,  0.3893, -0.0524, -0.0438],\n",
       "         [-0.0063, -0.0389,  0.0975, -0.1351],\n",
       "         [ 0.2280, -0.0552, -0.0588,  0.8083],\n",
       "         [-1.3316,  0.4914, -0.9688,  0.2328]], device='cuda:0',\n",
       "        requires_grad=True), tensor([[-0.5243,  1.2116, -0.5449, -0.4827],\n",
       "         [-0.1623, -0.4586,  0.0975, -0.8686],\n",
       "         [ 0.7715, -0.5757, -0.6175,  1.6885],\n",
       "         [-2.2453,  1.3330, -1.8619,  0.7907]], device='cuda:0'))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conjure] *",
   "language": "python",
   "name": "conda-env-conjure-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

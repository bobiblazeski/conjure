{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib notebook \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "\n",
    "from src.mesh.cube import NetCube, to_vertices\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dolphin mesh.\n",
    "trg_obj = os.path.join('./scenes/centered/meshes/centered.obj')\n",
    "\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale\n",
    "\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])#.to(device)\n",
    "trg_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = Namespace(\n",
    "    n = 82,\n",
    "    nfc=256, \n",
    "    min_nfc=128, \n",
    "    ker_size=3,\n",
    "    num_layer=5,\n",
    "    stride=1,\n",
    "    padd_size=0,\n",
    "    nc_im=3,\n",
    ")\n",
    "\n",
    "n = 32\n",
    "cube = NetCube(n, opt, kernel=7, sigma=2).to(device)\n",
    "\n",
    "#radii = torch.rand(3, device=v_ref.device, requires_grad=True)\n",
    "v, f = cube()\n",
    "# n_ref = compute_face_normals(v_ref, f_ref)\n",
    "print([f.shape for f in [v, f]])\n",
    "\n",
    "src_mesh =  Meshes(verts=[cube.get_start().to(device)], faces=[f])\n",
    "src_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.get_start().shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
    "new_src_mesh = src_mesh.offset_verts(v)\n",
    "sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
    "sample_trg, sample_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(cube.parameters(), lr=1.0, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(cube.parameters(), lr=0.0003)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of optimization steps\n",
    "Niter = 20000\n",
    "# Weight for the chamfer loss\n",
    "w_chamfer = 1.0 \n",
    "# Weight for mesh edge loss\n",
    "w_edge = 1.0 \n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 0.01 \n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 0.1 \n",
    "# Plot period for the losses\n",
    "plot_period = 250\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "chamfer_losses = []\n",
    "laplacian_losses = []\n",
    "edge_losses = []\n",
    "normal_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    v, _ = cube()\n",
    "    # Deform the mesh\n",
    "    new_src_mesh = src_mesh.offset_verts(v)\n",
    "    \n",
    "    # We sample 5k points from the surface of each mesh \n",
    "    sample_trg = sample_points_from_meshes(trg_mesh, 25000)\n",
    "    sample_src = sample_points_from_meshes(new_src_mesh, 25000)\n",
    "    \n",
    "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
    "    loss_chamfer, _ = chamfer_distance(sample_trg, sample_src)\n",
    "    \n",
    "    #if False:\n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
    "\n",
    "    # mesh normal consistency\n",
    "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
    "\n",
    "    # mesh laplacian smoothing\n",
    "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
    "\n",
    "    # Weighted sum of the losses\n",
    "    loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    #loss = loss_chamfer\n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "#     edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "#     normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "#     laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    #if i % plot_period == 0:\n",
    "    #    plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "chamfer_losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert =  cube.get_start().to(device) + v\n",
    "meshplot.plot(vert.detach().cpu().numpy(), f.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conjure] *",
   "language": "python",
   "name": "conda-env-conjure-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
